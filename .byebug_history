c
return
reload
array
return
self.class
reload
DataChunk.nearest_neighbors(:embedding, conversation_context_vector, distance: "euclidean").first(1).map(&:content)
DataChunk.nearest_neighbors(:embedding, conversation_context_vector, distance: "euclidean").first(1).each(&:content)
DataChunk.nearest_neighbors(:embedding, conversation_context_vector, distance: "euclidean").first(1)
exit
self
reload
exit
reload!
conversation_context_vector
DataChunk.nearest_neighbors(:embedding, ccv, distance: "euclidean").first(1).map(&:content)
DataChunk.nearest_neighbors(:embedding, ccv, distance: "euclidean").first(2).map(&:content)
DataChunk.nearest_neighbors(:embedding, ccv, distance: "euclidean").first(1).map(&:content)
DataChunk.nearest_neighbors(:embedding, ccv, distance: "euclidean").first(1).class
DataChunk.nearest_neighbors(:embedding, ccv, distance: "euclidean").first(1)
ccv = conversation_context_vector
v = _
conversation_context_vector
data_chunks
conversation_context_vector
exit
params
@chat.data_sources
@chat
data_source
return
data_source.valid?
exit
data_source.source
data_source
data_source.
data_source.save
data_source.errors.first
data_source.errors
data_source.valid?
data_source.errors
data_source
return
exit
redis
db
ENV
ENV['DOCKER_HOST_IP']
continue
exit
 vector.dig("usage", "total_tokens")
 vector.dig("usage", total_tokens")
 vector.dig("total_tokens")
vector
 vector.dig("total_token_count")
 vector.dig("data", 0)
vector
 vector.dig("data", 0, "embedding")
vector
exit
chunks
return
next
nex
next
current_user.chats.create
current_user.chats
continue
exit
@client.chat(
      parameters: {
        model: "gpt-3.5-turbo",
        messages: conversation[0...5],
        temperature: 0.2,
        stream: stream_proc
      }
    )
conversation[5][:role]
conversation[5]["role"]
conversation[5].role
conversation[5].class
conversation
conversation[5]
conversation.sixth
conversation.fifth
conversation.fourth
conversation.third
conversation.second
conversation.first
conversation.class
conversation
@client.chat(
      parameters: {
        model: "gpt-3.5-turbo",
        messages: conversation,
        temperature: 0.2,
        stream: stream_proc
      }
    )
conversation
exit
prok.call
prok.class
prok
exit
response.class
response
exit
next
stream_proc.class
